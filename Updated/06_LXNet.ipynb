{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renaming Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T12:51:12.222771Z",
     "iopub.status.busy": "2025-12-22T12:51:12.222276Z",
     "iopub.status.idle": "2025-12-22T12:51:12.241368Z",
     "shell.execute_reply": "2025-12-22T12:51:12.240672Z",
     "shell.execute_reply.started": "2025-12-22T12:51:12.222733Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symlinking: 00_Normal -> 00 Anatomia Normal\n",
      "Symlinking: 01_Inflammation -> 01 Processos Inflamat√≥rios Pulmonares (Pneumonia)\n",
      "Symlinking: 02_HighDensity -> 02 Maior Densidade (Derrame Pleural, Consolida√ß√£o Atelectasica, Hidrotorax, Empiema)\n",
      "Symlinking: 03_LowDensity -> 03 Menor Densidade (Pneumotorax, Pneumomediastino, Pneumoperitonio)\n",
      "Symlinking: 04_Obstructive -> 04 Doen√ßas Pulmonares Obstrutivas (Enfisema, Broncopneumonia, Bronquiectasia, Embolia)\n",
      "Symlinking: 05_Degenerative -> 05 Doen√ßas Infecciosas Degenerativas (Tuberculose, Sarcoidose, Proteinose, Fibrose)\n",
      "Symlinking: 06_Encapsulated -> 06 Les√µes Encapsuladas (Abscessos, N√≥dulos, Cistos, Massas Tumorais, Metastases)\n",
      "Symlinking: 07_Mediastinal -> 07 Altera√ß√µes de Mediastino (Pericardite, Malforma√ß√µes Arteriovenosas, Linfonodomegalias)\n",
      "Symlinking: 08_ChestChanges -> 08 Altera√ß√µes do T√≥rax (Atelectasias, Malforma√ß√µes, Agenesia, Hipoplasias)\n",
      "Done. Symlinked dataset is in: /kaggle/working/finaldataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "SRC_ROOT = \"/kaggle/input/finaldataset\"\n",
    "DST_ROOT = \"/kaggle/working/finaldataset\"\n",
    "\n",
    "rename_map = {\n",
    "    \"00 Anatomia Normal\": \"00_Normal\",\n",
    "    \"01 Processos Inflamat√≥rios Pulmonares (Pneumonia)\": \"01_Inflammation\",\n",
    "    \"02 Maior Densidade (Derrame Pleural, Consolida√ß√£o Atelectasica, Hidrotorax, Empiema)\": \"02_HighDensity\",\n",
    "    \"03 Menor Densidade (Pneumotorax, Pneumomediastino, Pneumoperitonio)\": \"03_LowDensity\",\n",
    "    \"04 Doen√ßas Pulmonares Obstrutivas (Enfisema, Broncopneumonia, Bronquiectasia, Embolia)\": \"04_Obstructive\",\n",
    "    \"05 Doen√ßas Infecciosas Degenerativas (Tuberculose, Sarcoidose, Proteinose, Fibrose)\": \"05_Degenerative\",\n",
    "    \"06 Les√µes Encapsuladas (Abscessos, N√≥dulos, Cistos, Massas Tumorais, Metastases)\": \"06_Encapsulated\",\n",
    "    \"07 Altera√ß√µes de Mediastino (Pericardite, Malforma√ß√µes Arteriovenosas, Linfonodomegalias)\": \"07_Mediastinal\",\n",
    "    \"08 Altera√ß√µes do T√≥rax (Atelectasias, Malforma√ß√µes, Agenesia, Hipoplasias)\": \"08_ChestChanges\",\n",
    "}\n",
    "\n",
    "os.makedirs(DST_ROOT, exist_ok=True)\n",
    "\n",
    "for old_name, new_name in rename_map.items():\n",
    "    src_path = os.path.join(SRC_ROOT, old_name)\n",
    "    dst_path = os.path.join(DST_ROOT, new_name)\n",
    "\n",
    "    if not os.path.isdir(src_path):\n",
    "        print(f\"Skipping (not found): {old_name}\")\n",
    "        continue\n",
    "\n",
    "    if os.path.exists(dst_path):\n",
    "        print(f\"Already exists: {new_name}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Symlinking: {new_name} -> {old_name}\")\n",
    "    os.symlink(src_path, dst_path)\n",
    "\n",
    "print(\"Done. Symlinked dataset is in:\", DST_ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-22T12:51:16.201954Z",
     "iopub.status.busy": "2025-12-22T12:51:16.201352Z",
     "iopub.status.idle": "2025-12-22T12:51:16.709328Z",
     "shell.execute_reply": "2025-12-22T12:51:16.708552Z",
     "shell.execute_reply.started": "2025-12-22T12:51:16.201924Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found classes: ['00_Normal', '01_Inflammation', '02_HighDensity', '03_LowDensity', '04_Obstructive', '05_Degenerative', '06_Encapsulated', '07_Mediastinal', '08_ChestChanges']\n",
      "[00_Normal] Total: 1000 -> Train: 800, Val: 100, Test: 100\n",
      "[01_Inflammation] Total: 1000 -> Train: 800, Val: 100, Test: 100\n",
      "[02_HighDensity] Total: 1000 -> Train: 800, Val: 100, Test: 100\n",
      "[03_LowDensity] Total: 1000 -> Train: 800, Val: 100, Test: 100\n",
      "[04_Obstructive] Total: 1000 -> Train: 800, Val: 100, Test: 100\n",
      "[05_Degenerative] Total: 1000 -> Train: 800, Val: 100, Test: 100\n",
      "[06_Encapsulated] Total: 1000 -> Train: 800, Val: 100, Test: 100\n",
      "[07_Mediastinal] Total: 1000 -> Train: 800, Val: 100, Test: 100\n",
      "[08_ChestChanges] Total: 1000 -> Train: 800, Val: 100, Test: 100\n",
      "\n",
      "‚úÖ Splitting complete.\n",
      "üìÅ Data located at: /kaggle/working/splited\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# ------------------------------\n",
    "# CONFIG\n",
    "# ------------------------------\n",
    "# Source: symlinked, renamed dataset\n",
    "data_dir = Path(\"/kaggle/working/finaldataset\")\n",
    "\n",
    "# Output: split dataset\n",
    "output_dir = Path(\"/kaggle/working/splited\")\n",
    "\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "# ------------------------------\n",
    "# CLEAN OUTPUT DIR\n",
    "# ------------------------------\n",
    "if output_dir.exists():\n",
    "    shutil.rmtree(output_dir)\n",
    "\n",
    "# ------------------------------\n",
    "# DISCOVER CLASSES\n",
    "# ------------------------------\n",
    "classes = sorted([d.name for d in data_dir.iterdir() if d.is_dir()])\n",
    "print(f\"Found classes: {classes}\")\n",
    "\n",
    "# ------------------------------\n",
    "# SPLIT DATA\n",
    "# ------------------------------\n",
    "for cls in classes:\n",
    "    class_dir = data_dir / cls\n",
    "    images = sorted(class_dir.glob(\"*\"))  # deterministic order\n",
    "    random.shuffle(images)\n",
    "\n",
    "    n_total = len(images)\n",
    "    if n_total == 0:\n",
    "        print(f\"[{cls}] Skipping (empty folder)\")\n",
    "        continue\n",
    "\n",
    "    n_train = int(n_total * train_ratio)\n",
    "    n_val = int(n_total * val_ratio)\n",
    "    n_test = n_total - n_train - n_val\n",
    "\n",
    "    splits = {\n",
    "        \"train\": images[:n_train],\n",
    "        \"val\": images[n_train:n_train + n_val],\n",
    "        \"test\": images[n_train + n_val:]\n",
    "    }\n",
    "\n",
    "    print(f\"[{cls}] Total: {n_total} -> \"\n",
    "          f\"Train: {n_train}, Val: {n_val}, Test: {n_test}\")\n",
    "\n",
    "    for split, files in splits.items():\n",
    "        split_dir = output_dir / split / cls\n",
    "        split_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for f in files:\n",
    "            dst = split_dir / f.name\n",
    "            if not dst.exists():\n",
    "                os.symlink(f, dst)\n",
    "\n",
    "print(f\"\\n‚úÖ Splitting complete.\")\n",
    "print(f\"üìÅ Data located at: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T13:04:30.903190Z",
     "iopub.status.busy": "2025-12-22T13:04:30.902455Z",
     "iopub.status.idle": "2025-12-22T13:04:32.583439Z",
     "shell.execute_reply": "2025-12-22T13:04:32.582635Z",
     "shell.execute_reply.started": "2025-12-22T13:04:30.903159Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7200 files belonging to 9 classes.\n",
      "Found 900 files belonging to 9 classes.\n",
      "Found 900 files belonging to 9 classes.\n",
      "Class names: ['00_Normal', '01_Inflammation', '02_HighDensity', '03_LowDensity', '04_Obstructive', '05_Degenerative', '06_Encapsulated', '07_Mediastinal', '08_ChestChanges']\n",
      "Number of classes: 9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "base_dir   = '/kaggle/working/splited'\n",
    "img_size   = (224, 224)\n",
    "batch_size = 48 #32 pretrained\n",
    "seed       = 42\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Load datasets\n",
    "train_ds_raw = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(base_dir, 'train'),\n",
    "    label_mode='categorical',\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "val_ds_raw = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(base_dir, 'val'),\n",
    "    label_mode='categorical',\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "test_ds_raw = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(base_dir, 'test'),\n",
    "    label_mode='categorical',\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "# Apply preprocessing (no AUTOTUNE, no cache)\n",
    "train_ds = train_ds_raw.map(preprocess)\n",
    "val_ds   = val_ds_raw.map(preprocess)\n",
    "test_ds  = test_ds_raw.map(preprocess)\n",
    "\n",
    "print(f\"Class names: {train_ds_raw.class_names}\")\n",
    "print(f\"Number of classes: {len(train_ds_raw.class_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper funntions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T12:51:45.334001Z",
     "iopub.status.busy": "2025-12-22T12:51:45.333571Z",
     "iopub.status.idle": "2025-12-22T12:51:45.432965Z",
     "shell.execute_reply": "2025-12-22T12:51:45.432366Z",
     "shell.execute_reply.started": "2025-12-22T12:51:45.333972Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "\n",
    "def save_auc_roc(model, dataset, class_names, save_path=\"auc_roc.png\"):\n",
    "   \n",
    "    # Get true labels and predictions\n",
    "    y_true = np.concatenate([y for x, y in dataset], axis=0)\n",
    "    y_pred = model.predict(dataset, verbose=0)\n",
    "    \n",
    "    n_classes = len(class_names)\n",
    "    \n",
    "    # Ensure y_true is one-hot encoded\n",
    "    if y_true.shape[1] != n_classes:\n",
    "        y_true = label_binarize(y_true, classes=range(n_classes))\n",
    "    \n",
    "    # Plot ROC for each class\n",
    "    plt.figure(figsize=(10,8))\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=2, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "    \n",
    "    # Plot diagonal line\n",
    "    plt.plot([0,1], [0,1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Multi-class ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T12:51:48.790283Z",
     "iopub.status.busy": "2025-12-22T12:51:48.789083Z",
     "iopub.status.idle": "2025-12-22T12:51:49.128744Z",
     "shell.execute_reply": "2025-12-22T12:51:49.128108Z",
     "shell.execute_reply.started": "2025-12-22T12:51:48.790239Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def save_confusion_matrix(model, dataset, class_names, save_path=\"confusion_matrix.png\"):\n",
    " \n",
    "    # Get true labels and predictions\n",
    "    y_true = np.concatenate([y for x, y in dataset], axis=0)\n",
    "    y_pred_probs = model.predict(dataset, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true_labels = np.argmax(y_true, axis=1)\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true_labels, y_pred)\n",
    "    \n",
    "    # Plot as heatmap\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T12:55:43.118697Z",
     "iopub.status.busy": "2025-12-22T12:55:43.117928Z",
     "iopub.status.idle": "2025-12-22T12:55:43.125891Z",
     "shell.execute_reply": "2025-12-22T12:55:43.125014Z",
     "shell.execute_reply.started": "2025-12-22T12:55:43.118664Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_curves(history, model_name=\"Model\", save_path=\".\"):\n",
    "\n",
    "    # Ensure save directory exists\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    acc = history.history.get(\"accuracy\")\n",
    "    val_acc = history.history.get(\"val_accuracy\")\n",
    "    loss = history.history.get(\"loss\")\n",
    "    val_loss = history.history.get(\"val_loss\")\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    # ---- Accuracy Plot ----\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, acc, label=\"Train Accuracy\")\n",
    "    plt.plot(epochs, val_acc, label=\"Validation Accuracy\")\n",
    "    plt.title(f\"{model_name} - Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # ---- Loss Plot ----\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, loss, label=\"Train Loss\")\n",
    "    plt.plot(epochs, val_loss, label=\"Validation Loss\")\n",
    "    plt.title(f\"{model_name} - Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Save plot\n",
    "    filename = f\"{model_name}_training_curves.png\"\n",
    "    full_path = os.path.join(save_path, filename)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(full_path, dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"‚úÖ Plot saved at: {full_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T12:51:55.969175Z",
     "iopub.status.busy": "2025-12-22T12:51:55.968558Z",
     "iopub.status.idle": "2025-12-22T12:51:55.975456Z",
     "shell.execute_reply": "2025-12-22T12:51:55.974516Z",
     "shell.execute_reply.started": "2025-12-22T12:51:55.969145Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "def save_classification_report(model, dataset, class_names, save_path=\"classification_report.png\"):\n",
    " \n",
    "    # Get true labels and predictions\n",
    "    y_true = np.concatenate([y for x, y in dataset], axis=0)\n",
    "    y_pred_probs = model.predict(dataset, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true_labels = np.argmax(y_true, axis=1)\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(y_true_labels, y_pred, target_names=class_names, output_dict=True)\n",
    "    \n",
    "    # Convert report to text for display\n",
    "    report_text = classification_report(y_true_labels, y_pred, target_names=class_names)\n",
    "    \n",
    "    # Plot report as figure\n",
    "    plt.figure(figsize=(10, len(class_names)*0.6 + 2))\n",
    "    plt.text(0, 1, \"Classification Report\", fontsize=14, fontweight='bold', va='top')\n",
    "    plt.text(0, 0.95, report_text, fontsize=12, fontfamily='monospace', va='top')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T12:51:59.392985Z",
     "iopub.status.busy": "2025-12-22T12:51:59.392713Z",
     "iopub.status.idle": "2025-12-22T12:51:59.399327Z",
     "shell.execute_reply": "2025-12-22T12:51:59.398662Z",
     "shell.execute_reply.started": "2025-12-22T12:51:59.392963Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def save_confusion_matrix(model, dataset, class_names, save_path=\"confusion_matrix.png\"):\n",
    " \n",
    "    # Get true labels and predictions\n",
    "    y_true = np.concatenate([y for x, y in dataset], axis=0)\n",
    "    y_pred_probs = model.predict(dataset, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true_labels = np.argmax(y_true, axis=1)\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true_labels, y_pred)\n",
    "    \n",
    "    # Plot as heatmap\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T12:52:02.587797Z",
     "iopub.status.busy": "2025-12-22T12:52:02.587228Z",
     "iopub.status.idle": "2025-12-22T12:52:02.595008Z",
     "shell.execute_reply": "2025-12-22T12:52:02.594057Z",
     "shell.execute_reply.started": "2025-12-22T12:52:02.587768Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "\n",
    "def save_auc_roc(model, dataset, class_names, save_path=\"auc_roc.png\"):\n",
    "   \n",
    "    # Get true labels and predictions\n",
    "    y_true = np.concatenate([y for x, y in dataset], axis=0)\n",
    "    y_pred = model.predict(dataset, verbose=0)\n",
    "    \n",
    "    n_classes = len(class_names)\n",
    "    \n",
    "    # Ensure y_true is one-hot encoded\n",
    "    if y_true.shape[1] != n_classes:\n",
    "        y_true = label_binarize(y_true, classes=range(n_classes))\n",
    "    \n",
    "    # Plot ROC for each class\n",
    "    plt.figure(figsize=(10,8))\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=2, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "    \n",
    "    # Plot diagonal line\n",
    "    plt.plot([0,1], [0,1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Multi-class ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T12:54:56.058557Z",
     "iopub.status.busy": "2025-12-22T12:54:56.058031Z",
     "iopub.status.idle": "2025-12-22T12:54:56.065319Z",
     "shell.execute_reply": "2025-12-22T12:54:56.064336Z",
     "shell.execute_reply.started": "2025-12-22T12:54:56.058529Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def evaluate_model_with_auc(model, dataset, dataset_name=\"Dataset\"):\n",
    "    \n",
    "    # 1. Standard model.evaluate() for loss and accuracy\n",
    "    loss, accuracy = model.evaluate(dataset, verbose=0)\n",
    "\n",
    "    # 2. Predict probabilities and get true labels\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for x_batch, y_batch in dataset:\n",
    "        preds = model.predict(x_batch, verbose=0)\n",
    "        y_true.append(y_batch.numpy())\n",
    "        y_pred.append(preds)\n",
    "\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "    # 3. Compute macro AUC for multi-class classification\n",
    "    auc = roc_auc_score(y_true, y_pred, average='macro', multi_class='ovr')\n",
    "\n",
    "    # 4. Print results\n",
    "    print(f\"{dataset_name} Loss: {loss:.4f}\")\n",
    "    print(f\"{dataset_name} Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"{dataset_name} AUC (macro): {auc:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"loss\": loss,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"auc_macro\": auc\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom CNN Arch. LXNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T12:52:06.064573Z",
     "iopub.status.busy": "2025-12-22T12:52:06.063916Z",
     "iopub.status.idle": "2025-12-22T12:52:06.959496Z",
     "shell.execute_reply": "2025-12-22T12:52:06.958633Z",
     "shell.execute_reply.started": "2025-12-22T12:52:06.064542Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "\n",
    "def conv_block(x, filters, k=3, s=1, name=None):\n",
    "    x = layers.Conv2D(filters, k, strides=s, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"swish\")(x)   \n",
    "    return x\n",
    "\n",
    "\n",
    "def build_lightxraynet(input_shape=(224,224,1), num_classes=9):\n",
    "    inp = keras.Input(shape=input_shape)\n",
    "    x = inp\n",
    "\n",
    "    # Stem\n",
    "    x = layers.Conv2D(32, 7, strides=2, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"swish\", name=\"stem_swish\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=3, strides=2, padding=\"same\", name=\"stem_pool\")(x)\n",
    "    x = layers.SpatialDropout2D(0.1)(x)\n",
    "    \n",
    "    # Block 1\n",
    "    x = conv_block(x, 48, k=3, s=1, name=\"b1_1\")\n",
    "    x = conv_block(x, 48, k=3, s=1, name=\"b1_2\")\n",
    "    x = layers.MaxPooling2D(pool_size=2, strides=2, name=\"pool1\")(x)  \n",
    "    x = layers.SpatialDropout2D(0.05)(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = conv_block(x, 72, k=3, s=1, name=\"b2_1\")\n",
    "    x = conv_block(x, 72, k=3, s=1, name=\"b2_2\")\n",
    "    x = layers.MaxPooling2D(pool_size=2, strides=2, name=\"pool2\")(x)  \n",
    "    x = layers.SpatialDropout2D(0.05)(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = conv_block(x, 128, k=3, s=1, name=\"b3_1\")\n",
    "    x = conv_block(x, 128, k=3, s=1, name=\"b3_2\")\n",
    "    \n",
    "    # Head\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    \n",
    "    return keras.Model(inp, out)\n",
    "\n",
    "model = build_lightxraynet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparams Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Nadam(learning_rate=0.0003),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_accuracy', patience=8, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-6, verbose=1),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=callbacks,\n",
    "    epochs=40,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save model as .h5\n",
    "modelName = \"LXNet\"\n",
    "class_names = train_ds_raw.class_names\n",
    "model.save(\"/kaggle/working/LightXRayNet.h5\")\n",
    "print(\"‚úÖ Model saved as /kaggle/working/LightXRayNet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val_results = evaluate_model_with_auc(model, val_ds, \"Validation\")\n",
    "test_results = evaluate_model_with_auc(model, test_ds, \"Test\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_training_curves(history, model_name=modelName, save_path=\"/kaggle/working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "save_classification_report(model, test_ds, class_names, save_path=\"classification_report.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "save_confusion_matrix(model, test_ds, class_names, save_path=\"confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "save_auc_roc(model, test_ds, class_names, save_path=\"auc_roc.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T13:05:31.315047Z",
     "iopub.status.busy": "2025-12-22T13:05:31.314627Z",
     "iopub.status.idle": "2025-12-22T13:05:32.817611Z",
     "shell.execute_reply": "2025-12-22T13:05:32.816958Z",
     "shell.execute_reply.started": "2025-12-22T13:05:31.315021Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "INPUT_SHAPE = (224, 224, 3)\n",
    "NUM_CLASSES = 9\n",
    "\n",
    "def resnet(\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    train_base=False,\n",
    "    model_name=\"ResNet50V2\"\n",
    "):\n",
    "    # Base model\n",
    "    base_model = keras.applications.ResNet50V2(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    base_model.trainable = train_base  # False for feature extraction\n",
    "\n",
    "    # Model input\n",
    "    inp = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Forward pass through base model\n",
    "    x = base_model(inp, training=False)\n",
    "\n",
    "    # Custom classification head\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    # Output layer\n",
    "    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    # Final model\n",
    "    model = keras.Model(inputs=inp, outputs=out, name=model_name)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = resnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=callbacks,\n",
    "    epochs=3,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "modelName = \"ResNet50V2\"\n",
    "class_names = train_ds_raw.class_names\n",
    "model.save(\"/kaggle/working/ResNet50V2.h5\")\n",
    "print(\"‚úÖ Model saved as /kaggle/working/ResNet50V2.h5\")\n",
    "\n",
    "val_results = evaluate_model_with_auc(model, val_ds, \"Validation\")\n",
    "test_results = evaluate_model_with_auc(model, test_ds, \"Test\") \n",
    "plot_training_curves(history, model_name=modelName, save_path=\"/kaggle/working\")\n",
    "\n",
    "\n",
    "save_classification_report(model, test_ds, class_names, save_path=\"classification_report.png\")\n",
    "save_confusion_matrix(model, test_ds, class_names, save_path=\"confusion_matrix.png\")\n",
    "save_auc_roc(model, test_ds, class_names, save_path=\"auc_roc.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9089599,
     "sourceId": 14246685,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
