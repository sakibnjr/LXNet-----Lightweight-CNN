{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14246685,"sourceType":"datasetVersion","datasetId":9089599}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Renaming Files","metadata":{}},{"cell_type":"code","source":"import os\n\nSRC_ROOT = \"/kaggle/input/finaldataset\"\nDST_ROOT = \"/kaggle/working/finaldataset\"\n\nrename_map = {\n    \"00 Anatomia Normal\": \"00_Normal\",\n    \"01 Processos Inflamat√≥rios Pulmonares (Pneumonia)\": \"01_Inflammation\",\n    \"02 Maior Densidade (Derrame Pleural, Consolida√ß√£o Atelectasica, Hidrotorax, Empiema)\": \"02_HighDensity\",\n    \"03 Menor Densidade (Pneumotorax, Pneumomediastino, Pneumoperitonio)\": \"03_LowDensity\",\n    \"04 Doen√ßas Pulmonares Obstrutivas (Enfisema, Broncopneumonia, Bronquiectasia, Embolia)\": \"04_Obstructive\",\n    \"05 Doen√ßas Infecciosas Degenerativas (Tuberculose, Sarcoidose, Proteinose, Fibrose)\": \"05_Degenerative\",\n    \"06 Les√µes Encapsuladas (Abscessos, N√≥dulos, Cistos, Massas Tumorais, Metastases)\": \"06_Encapsulated\",\n    \"07 Altera√ß√µes de Mediastino (Pericardite, Malforma√ß√µes Arteriovenosas, Linfonodomegalias)\": \"07_Mediastinal\",\n    \"08 Altera√ß√µes do T√≥rax (Atelectasias, Malforma√ß√µes, Agenesia, Hipoplasias)\": \"08_ChestChanges\",\n}\n\nos.makedirs(DST_ROOT, exist_ok=True)\n\nfor old_name, new_name in rename_map.items():\n    src_path = os.path.join(SRC_ROOT, old_name)\n    dst_path = os.path.join(DST_ROOT, new_name)\n\n    if not os.path.isdir(src_path):\n        print(f\"Skipping (not found): {old_name}\")\n        continue\n\n    if os.path.exists(dst_path):\n        print(f\"Already exists: {new_name}\")\n        continue\n\n    print(f\"Symlinking: {new_name} -> {old_name}\")\n    os.symlink(src_path, dst_path)\n\nprint(\"Done. Symlinked dataset is in:\", DST_ROOT)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T12:51:12.222276Z","iopub.execute_input":"2025-12-22T12:51:12.222771Z","iopub.status.idle":"2025-12-22T12:51:12.241368Z","shell.execute_reply.started":"2025-12-22T12:51:12.222733Z","shell.execute_reply":"2025-12-22T12:51:12.240672Z"}},"outputs":[{"name":"stdout","text":"Symlinking: 00_Normal -> 00 Anatomia Normal\nSymlinking: 01_Inflammation -> 01 Processos Inflamat√≥rios Pulmonares (Pneumonia)\nSymlinking: 02_HighDensity -> 02 Maior Densidade (Derrame Pleural, Consolida√ß√£o Atelectasica, Hidrotorax, Empiema)\nSymlinking: 03_LowDensity -> 03 Menor Densidade (Pneumotorax, Pneumomediastino, Pneumoperitonio)\nSymlinking: 04_Obstructive -> 04 Doen√ßas Pulmonares Obstrutivas (Enfisema, Broncopneumonia, Bronquiectasia, Embolia)\nSymlinking: 05_Degenerative -> 05 Doen√ßas Infecciosas Degenerativas (Tuberculose, Sarcoidose, Proteinose, Fibrose)\nSymlinking: 06_Encapsulated -> 06 Les√µes Encapsuladas (Abscessos, N√≥dulos, Cistos, Massas Tumorais, Metastases)\nSymlinking: 07_Mediastinal -> 07 Altera√ß√µes de Mediastino (Pericardite, Malforma√ß√µes Arteriovenosas, Linfonodomegalias)\nSymlinking: 08_ChestChanges -> 08 Altera√ß√µes do T√≥rax (Atelectasias, Malforma√ß√µes, Agenesia, Hipoplasias)\nDone. Symlinked dataset is in: /kaggle/working/finaldataset\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Data Split","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nfrom pathlib import Path\nimport shutil\n\n# ------------------------------\n# CONFIG\n# ------------------------------\n# Source: symlinked, renamed dataset\ndata_dir = Path(\"/kaggle/working/finaldataset\")\n\n# Output: split dataset\noutput_dir = Path(\"/kaggle/working/splited\")\n\ntrain_ratio = 0.8\nval_ratio = 0.1\ntest_ratio = 0.1\nseed = 42\n\nrandom.seed(seed)\n\n# ------------------------------\n# CLEAN OUTPUT DIR\n# ------------------------------\nif output_dir.exists():\n    shutil.rmtree(output_dir)\n\n# ------------------------------\n# DISCOVER CLASSES\n# ------------------------------\nclasses = sorted([d.name for d in data_dir.iterdir() if d.is_dir()])\nprint(f\"Found classes: {classes}\")\n\n# ------------------------------\n# SPLIT DATA\n# ------------------------------\nfor cls in classes:\n    class_dir = data_dir / cls\n    images = sorted(class_dir.glob(\"*\"))  # deterministic order\n    random.shuffle(images)\n\n    n_total = len(images)\n    if n_total == 0:\n        print(f\"[{cls}] Skipping (empty folder)\")\n        continue\n\n    n_train = int(n_total * train_ratio)\n    n_val = int(n_total * val_ratio)\n    n_test = n_total - n_train - n_val\n\n    splits = {\n        \"train\": images[:n_train],\n        \"val\": images[n_train:n_train + n_val],\n        \"test\": images[n_train + n_val:]\n    }\n\n    print(f\"[{cls}] Total: {n_total} -> \"\n          f\"Train: {n_train}, Val: {n_val}, Test: {n_test}\")\n\n    for split, files in splits.items():\n        split_dir = output_dir / split / cls\n        split_dir.mkdir(parents=True, exist_ok=True)\n\n        for f in files:\n            dst = split_dir / f.name\n            if not dst.exists():\n                os.symlink(f, dst)\n\nprint(f\"\\n‚úÖ Splitting complete.\")\nprint(f\"üìÅ Data located at: {output_dir}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-22T12:51:16.201352Z","iopub.execute_input":"2025-12-22T12:51:16.201954Z","iopub.status.idle":"2025-12-22T12:51:16.709328Z","shell.execute_reply.started":"2025-12-22T12:51:16.201924Z","shell.execute_reply":"2025-12-22T12:51:16.708552Z"}},"outputs":[{"name":"stdout","text":"Found classes: ['00_Normal', '01_Inflammation', '02_HighDensity', '03_LowDensity', '04_Obstructive', '05_Degenerative', '06_Encapsulated', '07_Mediastinal', '08_ChestChanges']\n[00_Normal] Total: 1000 -> Train: 800, Val: 100, Test: 100\n[01_Inflammation] Total: 1000 -> Train: 800, Val: 100, Test: 100\n[02_HighDensity] Total: 1000 -> Train: 800, Val: 100, Test: 100\n[03_LowDensity] Total: 1000 -> Train: 800, Val: 100, Test: 100\n[04_Obstructive] Total: 1000 -> Train: 800, Val: 100, Test: 100\n[05_Degenerative] Total: 1000 -> Train: 800, Val: 100, Test: 100\n[06_Encapsulated] Total: 1000 -> Train: 800, Val: 100, Test: 100\n[07_Mediastinal] Total: 1000 -> Train: 800, Val: 100, Test: 100\n[08_ChestChanges] Total: 1000 -> Train: 800, Val: 100, Test: 100\n\n‚úÖ Splitting complete.\nüìÅ Data located at: /kaggle/working/splited\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Data Load","metadata":{}},{"cell_type":"code","source":"import os\nimport tensorflow as tf\nimport numpy as np\n\nbase_dir   = '/kaggle/working/splited'\nimg_size   = (224, 224)\nbatch_size = 48 #32 pretrained\nseed       = 42\n\ntf.random.set_seed(seed)\nnp.random.seed(seed)\n\n# Load datasets\ntrain_ds_raw = tf.keras.utils.image_dataset_from_directory(\n    os.path.join(base_dir, 'train'),\n    label_mode='categorical',\n    image_size=img_size,\n    batch_size=batch_size,\n    shuffle=True,\n    seed=seed\n)\n\nval_ds_raw = tf.keras.utils.image_dataset_from_directory(\n    os.path.join(base_dir, 'val'),\n    label_mode='categorical',\n    image_size=img_size,\n    batch_size=batch_size,\n    shuffle=False,\n    seed=seed\n)\n\ntest_ds_raw = tf.keras.utils.image_dataset_from_directory(\n    os.path.join(base_dir, 'test'),\n    label_mode='categorical',\n    image_size=img_size,\n    batch_size=batch_size,\n    shuffle=False,\n    seed=seed\n)\n\n# Preprocessing function\ndef preprocess(image, label):\n    image = tf.image.rgb_to_grayscale(image)\n    image = tf.cast(image, tf.float32) / 255.0\n    return image, label\n\n# Apply preprocessing (no AUTOTUNE, no cache)\ntrain_ds = train_ds_raw.map(preprocess)\nval_ds   = val_ds_raw.map(preprocess)\ntest_ds  = test_ds_raw.map(preprocess)\n\nprint(f\"Class names: {train_ds_raw.class_names}\")\nprint(f\"Number of classes: {len(train_ds_raw.class_names)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T13:04:30.902455Z","iopub.execute_input":"2025-12-22T13:04:30.903190Z","iopub.status.idle":"2025-12-22T13:04:32.583439Z","shell.execute_reply.started":"2025-12-22T13:04:30.903159Z","shell.execute_reply":"2025-12-22T13:04:32.582635Z"}},"outputs":[{"name":"stdout","text":"Found 7200 files belonging to 9 classes.\nFound 900 files belonging to 9 classes.\nFound 900 files belonging to 9 classes.\nClass names: ['00_Normal', '01_Inflammation', '02_HighDensity', '03_LowDensity', '04_Obstructive', '05_Degenerative', '06_Encapsulated', '07_Mediastinal', '08_ChestChanges']\nNumber of classes: 9\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"# Helper funntions ","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nimport numpy as np\n\ndef save_auc_roc(model, dataset, class_names, save_path=\"auc_roc.png\"):\n   \n    # Get true labels and predictions\n    y_true = np.concatenate([y for x, y in dataset], axis=0)\n    y_pred = model.predict(dataset, verbose=0)\n    \n    n_classes = len(class_names)\n    \n    # Ensure y_true is one-hot encoded\n    if y_true.shape[1] != n_classes:\n        y_true = label_binarize(y_true, classes=range(n_classes))\n    \n    # Plot ROC for each class\n    plt.figure(figsize=(10,8))\n    \n    for i in range(n_classes):\n        fpr, tpr, _ = roc_curve(y_true[:, i], y_pred[:, i])\n        roc_auc = auc(fpr, tpr)\n        plt.plot(fpr, tpr, lw=2, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n    \n    # Plot diagonal line\n    plt.plot([0,1], [0,1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Multi-class ROC Curve')\n    plt.legend(loc='lower right')\n    plt.grid(True)\n    plt.tight_layout()\n    \n    plt.savefig(save_path)\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T12:51:45.333571Z","iopub.execute_input":"2025-12-22T12:51:45.334001Z","iopub.status.idle":"2025-12-22T12:51:45.432965Z","shell.execute_reply.started":"2025-12-22T12:51:45.333972Z","shell.execute_reply":"2025-12-22T12:51:45.432366Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\n\ndef save_confusion_matrix(model, dataset, class_names, save_path=\"confusion_matrix.png\"):\n \n    # Get true labels and predictions\n    y_true = np.concatenate([y for x, y in dataset], axis=0)\n    y_pred_probs = model.predict(dataset, verbose=0)\n    y_pred = np.argmax(y_pred_probs, axis=1)\n    y_true_labels = np.argmax(y_true, axis=1)\n    \n    # Compute confusion matrix\n    cm = confusion_matrix(y_true_labels, y_pred)\n    \n    # Plot as heatmap\n    plt.figure(figsize=(8,6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=class_names, yticklabels=class_names)\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.title('Confusion Matrix')\n    plt.tight_layout()\n    plt.savefig(save_path)\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T12:51:48.789083Z","iopub.execute_input":"2025-12-22T12:51:48.790283Z","iopub.status.idle":"2025-12-22T12:51:49.128744Z","shell.execute_reply.started":"2025-12-22T12:51:48.790239Z","shell.execute_reply":"2025-12-22T12:51:49.128108Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\n\ndef plot_training_curves(history, model_name=\"Model\", save_path=\".\"):\n\n    # Ensure save directory exists\n    os.makedirs(save_path, exist_ok=True)\n\n    acc = history.history.get(\"accuracy\")\n    val_acc = history.history.get(\"val_accuracy\")\n    loss = history.history.get(\"loss\")\n    val_loss = history.history.get(\"val_loss\")\n\n    epochs = range(1, len(acc) + 1)\n\n    plt.figure(figsize=(14, 5))\n\n    # ---- Accuracy Plot ----\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, acc, label=\"Train Accuracy\")\n    plt.plot(epochs, val_acc, label=\"Validation Accuracy\")\n    plt.title(f\"{model_name} - Accuracy\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n    plt.grid(True)\n\n    # ---- Loss Plot ----\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, loss, label=\"Train Loss\")\n    plt.plot(epochs, val_loss, label=\"Validation Loss\")\n    plt.title(f\"{model_name} - Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.grid(True)\n\n    # Save plot\n    filename = f\"{model_name}_training_curves.png\"\n    full_path = os.path.join(save_path, filename)\n    plt.tight_layout()\n    plt.savefig(full_path, dpi=300)\n    plt.show()\n    plt.close()\n\n    print(f\"‚úÖ Plot saved at: {full_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T12:55:43.117928Z","iopub.execute_input":"2025-12-22T12:55:43.118697Z","iopub.status.idle":"2025-12-22T12:55:43.125891Z","shell.execute_reply.started":"2025-12-22T12:55:43.118664Z","shell.execute_reply":"2025-12-22T12:55:43.125014Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report\nimport numpy as np\n\ndef save_classification_report(model, dataset, class_names, save_path=\"classification_report.png\"):\n \n    # Get true labels and predictions\n    y_true = np.concatenate([y for x, y in dataset], axis=0)\n    y_pred_probs = model.predict(dataset, verbose=0)\n    y_pred = np.argmax(y_pred_probs, axis=1)\n    y_true_labels = np.argmax(y_true, axis=1)\n    \n    # Generate classification report\n    report = classification_report(y_true_labels, y_pred, target_names=class_names, output_dict=True)\n    \n    # Convert report to text for display\n    report_text = classification_report(y_true_labels, y_pred, target_names=class_names)\n    \n    # Plot report as figure\n    plt.figure(figsize=(10, len(class_names)*0.6 + 2))\n    plt.text(0, 1, \"Classification Report\", fontsize=14, fontweight='bold', va='top')\n    plt.text(0, 0.95, report_text, fontsize=12, fontfamily='monospace', va='top')\n    plt.axis('off')\n    plt.tight_layout()\n    plt.savefig(save_path)\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T12:51:55.968558Z","iopub.execute_input":"2025-12-22T12:51:55.969175Z","iopub.status.idle":"2025-12-22T12:51:55.975456Z","shell.execute_reply.started":"2025-12-22T12:51:55.969145Z","shell.execute_reply":"2025-12-22T12:51:55.974516Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\n\ndef save_confusion_matrix(model, dataset, class_names, save_path=\"confusion_matrix.png\"):\n \n    # Get true labels and predictions\n    y_true = np.concatenate([y for x, y in dataset], axis=0)\n    y_pred_probs = model.predict(dataset, verbose=0)\n    y_pred = np.argmax(y_pred_probs, axis=1)\n    y_true_labels = np.argmax(y_true, axis=1)\n    \n    # Compute confusion matrix\n    cm = confusion_matrix(y_true_labels, y_pred)\n    \n    # Plot as heatmap\n    plt.figure(figsize=(8,6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=class_names, yticklabels=class_names)\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.title('Confusion Matrix')\n    plt.tight_layout()\n    plt.savefig(save_path)\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T12:51:59.392713Z","iopub.execute_input":"2025-12-22T12:51:59.392985Z","iopub.status.idle":"2025-12-22T12:51:59.399327Z","shell.execute_reply.started":"2025-12-22T12:51:59.392963Z","shell.execute_reply":"2025-12-22T12:51:59.398662Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nimport numpy as np\n\ndef save_auc_roc(model, dataset, class_names, save_path=\"auc_roc.png\"):\n   \n    # Get true labels and predictions\n    y_true = np.concatenate([y for x, y in dataset], axis=0)\n    y_pred = model.predict(dataset, verbose=0)\n    \n    n_classes = len(class_names)\n    \n    # Ensure y_true is one-hot encoded\n    if y_true.shape[1] != n_classes:\n        y_true = label_binarize(y_true, classes=range(n_classes))\n    \n    # Plot ROC for each class\n    plt.figure(figsize=(10,8))\n    \n    for i in range(n_classes):\n        fpr, tpr, _ = roc_curve(y_true[:, i], y_pred[:, i])\n        roc_auc = auc(fpr, tpr)\n        plt.plot(fpr, tpr, lw=2, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n    \n    # Plot diagonal line\n    plt.plot([0,1], [0,1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Multi-class ROC Curve')\n    plt.legend(loc='lower right')\n    plt.grid(True)\n    plt.tight_layout()\n    \n    plt.savefig(save_path)\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T12:52:02.587228Z","iopub.execute_input":"2025-12-22T12:52:02.587797Z","iopub.status.idle":"2025-12-22T12:52:02.595008Z","shell.execute_reply.started":"2025-12-22T12:52:02.587768Z","shell.execute_reply":"2025-12-22T12:52:02.594057Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import roc_auc_score\n\ndef evaluate_model_with_auc(model, dataset, dataset_name=\"Dataset\"):\n    \n    # 1. Standard model.evaluate() for loss and accuracy\n    loss, accuracy = model.evaluate(dataset, verbose=0)\n\n    # 2. Predict probabilities and get true labels\n    y_true = []\n    y_pred = []\n\n    for x_batch, y_batch in dataset:\n        preds = model.predict(x_batch, verbose=0)\n        y_true.append(y_batch.numpy())\n        y_pred.append(preds)\n\n    y_true = np.concatenate(y_true, axis=0)\n    y_pred = np.concatenate(y_pred, axis=0)\n\n    # 3. Compute macro AUC for multi-class classification\n    auc = roc_auc_score(y_true, y_pred, average='macro', multi_class='ovr')\n\n    # 4. Print results\n    print(f\"{dataset_name} Loss: {loss:.4f}\")\n    print(f\"{dataset_name} Accuracy: {accuracy:.4f}\")\n    print(f\"{dataset_name} AUC (macro): {auc:.4f}\")\n\n    return {\n        \"loss\": loss,\n        \"accuracy\": accuracy,\n        \"auc_macro\": auc\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T12:54:56.058031Z","iopub.execute_input":"2025-12-22T12:54:56.058557Z","iopub.status.idle":"2025-12-22T12:54:56.065319Z","shell.execute_reply.started":"2025-12-22T12:54:56.058529Z","shell.execute_reply":"2025-12-22T12:54:56.064336Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# Custom CNN Arch. LXNet","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, regularizers\n\n\ndef conv_block(x, filters, k=3, s=1, name=None):\n    x = layers.Conv2D(filters, k, strides=s, padding=\"same\", use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"swish\")(x)   \n    return x\n\n\ndef build_lightxraynet(input_shape=(224,224,1), num_classes=9):\n    inp = keras.Input(shape=input_shape)\n    x = inp\n\n    # Stem\n    x = layers.Conv2D(32, 7, strides=2, padding=\"same\", use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"swish\", name=\"stem_swish\")(x)\n    x = layers.MaxPooling2D(pool_size=3, strides=2, padding=\"same\", name=\"stem_pool\")(x)\n    x = layers.SpatialDropout2D(0.1)(x)\n    \n    # Block 1\n    x = conv_block(x, 48, k=3, s=1, name=\"b1_1\")\n    x = conv_block(x, 48, k=3, s=1, name=\"b1_2\")\n    x = layers.MaxPooling2D(pool_size=2, strides=2, name=\"pool1\")(x)  \n    x = layers.SpatialDropout2D(0.05)(x)\n\n    # Block 2\n    x = conv_block(x, 72, k=3, s=1, name=\"b2_1\")\n    x = conv_block(x, 72, k=3, s=1, name=\"b2_2\")\n    x = layers.MaxPooling2D(pool_size=2, strides=2, name=\"pool2\")(x)  \n    x = layers.SpatialDropout2D(0.05)(x)\n\n    # Block 3\n    x = conv_block(x, 128, k=3, s=1, name=\"b3_1\")\n    x = conv_block(x, 128, k=3, s=1, name=\"b3_2\")\n    \n    # Head\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dropout(0.3)(x)\n    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n    \n    return keras.Model(inp, out)\n\n# Build model with Swish\nmodel = build_lightxraynet()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T12:52:06.063916Z","iopub.execute_input":"2025-12-22T12:52:06.064573Z","iopub.status.idle":"2025-12-22T12:52:06.959496Z","shell.execute_reply.started":"2025-12-22T12:52:06.064542Z","shell.execute_reply":"2025-12-22T12:52:06.958633Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# Hyperparams Setup","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Nadam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nmodel.compile(\n    optimizer=Nadam(learning_rate=0.0003),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\ncallbacks = [\n    EarlyStopping(monitor='val_accuracy', patience=8, restore_best_weights=True, verbose=1),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-6, verbose=1),\n]\n\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    callbacks=callbacks,\n    epochs=40,\n    verbose=1\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save model as .h5\nmodelName = \"LXNet\"\nclass_names = train_ds_raw.class_names\nmodel.save(\"/kaggle/working/LightXRayNet.h5\")\nprint(\"‚úÖ Model saved as /kaggle/working/LightXRayNet.h5\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_results = evaluate_model_with_auc(model, val_ds, \"Validation\")\ntest_results = evaluate_model_with_auc(model, test_ds, \"Test\") ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_training_curves(history, model_name=modelName, save_path=\"/kaggle/working\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_classification_report(model, test_ds, class_names, save_path=\"classification_report.png\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_confusion_matrix(model, test_ds, class_names, save_path=\"confusion_matrix.png\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_auc_roc(model, test_ds, class_names, save_path=\"auc_roc.png\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Resnet","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n\nINPUT_SHAPE = (224, 224, 3)\nNUM_CLASSES = 9\n\ndef resnet(\n    input_shape=INPUT_SHAPE,\n    num_classes=NUM_CLASSES,\n    train_base=False,\n    model_name=\"ResNet50V2\"\n):\n    # Base model\n    base_model = keras.applications.ResNet50V2(\n        include_top=False,\n        weights=\"imagenet\",\n        input_shape=input_shape\n    )\n    base_model.trainable = train_base  # False for feature extraction\n\n    # Model input\n    inp = keras.Input(shape=input_shape)\n\n    # Forward pass through base model\n    x = base_model(inp, training=False)\n\n    # Custom classification head\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dropout(0.5)(x)\n    x = layers.Dense(256, activation=\"relu\")(x)\n    x = layers.Dropout(0.5)(x)\n\n    # Output layer\n    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n\n    # Final model\n    model = keras.Model(inputs=inp, outputs=out, name=model_name)\n\n    return model\n\nmodel = resnet()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T13:05:31.314627Z","iopub.execute_input":"2025-12-22T13:05:31.315047Z","iopub.status.idle":"2025-12-22T13:05:32.817611Z","shell.execute_reply.started":"2025-12-22T13:05:31.315021Z","shell.execute_reply":"2025-12-22T13:05:32.816958Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nmodel.compile(\n    optimizer=Adam(learning_rate=0.001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\ncallbacks = [\n    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1),\n]\n\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    callbacks=callbacks,\n    epochs=3,\n    verbose=1\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nmodelName = \"ResNet50V2\"\nclass_names = train_ds_raw.class_names\nmodel.save(\"/kaggle/working/ResNet50V2.h5\")\nprint(\"‚úÖ Model saved as /kaggle/working/ResNet50V2.h5\")\n\nval_results = evaluate_model_with_auc(model, val_ds, \"Validation\")\ntest_results = evaluate_model_with_auc(model, test_ds, \"Test\") \nplot_training_curves(history, model_name=modelName, save_path=\"/kaggle/working\")\n\n\nsave_classification_report(model, test_ds, class_names, save_path=\"classification_report.png\")\nsave_confusion_matrix(model, test_ds, class_names, save_path=\"confusion_matrix.png\")\nsave_auc_roc(model, test_ds, class_names, save_path=\"auc_roc.png\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}